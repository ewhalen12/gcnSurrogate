{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to gragh convolutional surrogate models\n",
    "Eamon Whalen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "from gcnSurrogate.models.feastnetSurrogateModel import FeaStNet\n",
    "from gcnSurrogate.readers.loadConmechGraphs import loadConmechGraphs\n",
    "from gcnSurrogate.visualization.altTrussViz import plotTruss, interactiveErrorPlot\n",
    "from gcnSurrogate.util.gcnSurrogateUtil import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.137562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.740254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.004530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.010635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.016778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.032392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.419552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             maxes\n",
       "count  1000.000000\n",
       "mean      0.137562\n",
       "std       1.740254\n",
       "min       0.004530\n",
       "25%       0.010635\n",
       "50%       0.016778\n",
       "75%       0.032392\n",
       "max      46.419552"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDir = 'data/2D_Truss_v1.3/conmech/design_7_N_1000/'\n",
    "allGraphsUnfiltered = loadConmechGraphs(dataDir)\n",
    "\n",
    "maxes = [max(np.abs(graph.y.numpy().flatten())) for graph in allGraphsUnfiltered]\n",
    "source = pd.DataFrame(maxes, columns=['maxes'])\n",
    "source.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotTruss(allGraphsUnfiltered[0], showDeformed=True, defScale=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filter and partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.019962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.013149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.004530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.010309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.014975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.026453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.067472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            maxes\n",
       "count  900.000000\n",
       "mean     0.019962\n",
       "std      0.013149\n",
       "min      0.004530\n",
       "25%      0.010309\n",
       "50%      0.014975\n",
       "75%      0.026453\n",
       "max      0.067472"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allGraphs = filterbyDisp(allGraphsUnfiltered, 0.9)\n",
    "trainData, valData, testData = partitionGraphList(allGraphs)\n",
    "\n",
    "maxes = [max(np.abs(graph.y.numpy().flatten())) for graph in allGraphs]\n",
    "source = pd.DataFrame(maxes, columns=['maxes'])\n",
    "source.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train a GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0   trainLoss: 9.3906e-01   valLoss:9.6108e-01  time: 1.75e+00\n",
      "epoch: 1   trainLoss: 7.7934e-01   valLoss:9.5168e-01  time: 1.46e+00\n",
      "epoch: 2   trainLoss: 6.4415e-01   valLoss:9.7877e-01  time: 1.43e+00\n",
      "epoch: 3   trainLoss: 5.1322e-01   valLoss:1.0715e+00  time: 1.43e+00\n",
      "epoch: 4   trainLoss: 4.4452e-01   valLoss:1.3035e+00  time: 1.42e+00\n",
      "epoch: 5   trainLoss: 3.9518e-01   valLoss:1.8738e+00  time: 1.40e+00\n",
      "epoch: 6   trainLoss: 3.5037e-01   valLoss:2.5668e+00  time: 1.40e+00\n",
      "epoch: 7   trainLoss: 2.9780e-01   valLoss:2.6705e+00  time: 1.44e+00\n",
      "epoch: 8   trainLoss: 2.3464e-01   valLoss:1.4771e+00  time: 1.45e+00\n",
      "epoch: 9   trainLoss: 2.3480e-01   valLoss:5.1360e-01  time: 1.44e+00\n",
      "epoch: 10   trainLoss: 2.2997e-01   valLoss:3.6351e-01  time: 1.45e+00\n",
      "epoch: 11   trainLoss: 2.3081e-01   valLoss:4.8568e-01  time: 1.44e+00\n",
      "epoch: 12   trainLoss: 1.8157e-01   valLoss:5.6041e-01  time: 1.41e+00\n",
      "epoch: 13   trainLoss: 2.2463e-01   valLoss:3.3168e-01  time: 1.41e+00\n",
      "epoch: 14   trainLoss: 1.8119e-01   valLoss:1.5613e+00  time: 1.44e+00\n",
      "epoch: 15   trainLoss: 1.6215e-01   valLoss:1.6778e+00  time: 1.45e+00\n",
      "epoch: 16   trainLoss: 1.4817e-01   valLoss:1.3534e+00  time: 1.47e+00\n",
      "epoch: 17   trainLoss: 1.3100e-01   valLoss:7.9547e-01  time: 1.43e+00\n",
      "epoch: 18   trainLoss: 1.3354e-01   valLoss:5.9061e-01  time: 1.44e+00\n",
      "epoch: 19   trainLoss: 1.2385e-01   valLoss:5.4127e-01  time: 1.46e+00\n",
      "epoch: 20   trainLoss: 1.2990e-01   valLoss:7.3642e-01  time: 1.45e+00\n",
      "epoch: 21   trainLoss: 1.5000e-01   valLoss:3.0243e-01  time: 1.43e+00\n",
      "epoch: 22   trainLoss: 1.0561e-01   valLoss:4.3462e-01  time: 1.42e+00\n",
      "epoch: 23   trainLoss: 9.7199e-02   valLoss:5.2574e-01  time: 1.42e+00\n",
      "epoch: 24   trainLoss: 9.6677e-02   valLoss:3.4085e-01  time: 1.43e+00\n",
      "epoch: 25   trainLoss: 9.0848e-02   valLoss:2.1116e-01  time: 1.44e+00\n",
      "epoch: 26   trainLoss: 8.1039e-02   valLoss:2.6804e-01  time: 1.45e+00\n",
      "epoch: 27   trainLoss: 8.3589e-02   valLoss:1.8005e-01  time: 1.44e+00\n",
      "epoch: 28   trainLoss: 8.9502e-02   valLoss:1.9418e-01  time: 1.44e+00\n",
      "epoch: 29   trainLoss: 7.2694e-02   valLoss:2.5492e-01  time: 1.43e+00\n",
      "epoch: 30   trainLoss: 8.0718e-02   valLoss:2.0241e-01  time: 1.45e+00\n",
      "epoch: 31   trainLoss: 7.2891e-02   valLoss:1.9257e-01  time: 1.44e+00\n",
      "epoch: 32   trainLoss: 7.0114e-02   valLoss:2.1377e-01  time: 1.42e+00\n",
      "epoch: 33   trainLoss: 9.9600e-02   valLoss:1.7828e-01  time: 1.43e+00\n",
      "epoch: 34   trainLoss: 7.2415e-02   valLoss:1.6081e-01  time: 1.45e+00\n",
      "epoch: 35   trainLoss: 5.5346e-02   valLoss:2.4187e-01  time: 1.47e+00\n",
      "epoch: 36   trainLoss: 5.7829e-02   valLoss:1.2257e-01  time: 1.44e+00\n",
      "epoch: 37   trainLoss: 4.8876e-02   valLoss:1.9434e-01  time: 1.43e+00\n",
      "epoch: 38   trainLoss: 5.4784e-02   valLoss:1.6007e-01  time: 1.43e+00\n",
      "epoch: 39   trainLoss: 5.2001e-02   valLoss:1.3387e-01  time: 1.43e+00\n",
      "epoch: 40   trainLoss: 4.3153e-02   valLoss:1.4768e-01  time: 1.44e+00\n",
      "epoch: 41   trainLoss: 7.0041e-02   valLoss:1.6680e-01  time: 1.47e+00\n",
      "epoch: 42   trainLoss: 6.7829e-02   valLoss:1.7348e-01  time: 1.44e+00\n",
      "epoch: 43   trainLoss: 4.4818e-02   valLoss:1.7820e-01  time: 1.44e+00\n",
      "epoch: 44   trainLoss: 5.6941e-02   valLoss:2.5981e-01  time: 1.43e+00\n",
      "epoch: 45   trainLoss: 6.1229e-02   valLoss:1.3832e-01  time: 1.44e+00\n",
      "epoch: 46   trainLoss: 6.3999e-02   valLoss:1.3197e-01  time: 1.45e+00\n",
      "epoch: 47   trainLoss: 6.5754e-02   valLoss:1.0381e-01  time: 1.46e+00\n",
      "epoch: 48   trainLoss: 5.5983e-02   valLoss:2.0171e-01  time: 1.42e+00\n",
      "epoch: 49   trainLoss: 5.4551e-02   valLoss:1.6983e-01  time: 1.44e+00\n",
      "epoch: 50   trainLoss: 5.8938e-02   valLoss:2.4523e-01  time: 1.44e+00\n",
      "epoch: 51   trainLoss: 6.4673e-02   valLoss:1.2938e-01  time: 1.43e+00\n",
      "epoch: 52   trainLoss: 6.0748e-02   valLoss:3.1632e-01  time: 1.47e+00\n",
      "epoch: 53   trainLoss: 6.7779e-02   valLoss:1.3097e-01  time: 1.45e+00\n",
      "epoch: 54   trainLoss: 8.3141e-02   valLoss:1.3566e-01  time: 1.45e+00\n",
      "epoch: 55   trainLoss: 6.4430e-02   valLoss:1.6240e-01  time: 1.45e+00\n",
      "epoch: 56   trainLoss: 4.6338e-02   valLoss:1.0923e-01  time: 1.45e+00\n",
      "epoch: 57   trainLoss: 5.6475e-02   valLoss:1.5946e-01  time: 1.44e+00\n",
      "epoch: 58   trainLoss: 5.8173e-02   valLoss:1.3093e-01  time: 1.44e+00\n",
      "epoch: 59   trainLoss: 5.3056e-02   valLoss:1.1896e-01  time: 1.46e+00\n",
      "epoch: 60   trainLoss: 4.8296e-02   valLoss:1.3772e-01  time: 1.44e+00\n",
      "epoch: 61   trainLoss: 4.4342e-02   valLoss:1.3378e-01  time: 1.45e+00\n",
      "epoch: 62   trainLoss: 6.1593e-02   valLoss:2.0837e-01  time: 1.44e+00\n",
      "epoch: 63   trainLoss: 7.3324e-02   valLoss:1.5277e-01  time: 1.43e+00\n",
      "epoch: 64   trainLoss: 4.7618e-02   valLoss:1.5738e-01  time: 1.45e+00\n",
      "epoch: 65   trainLoss: 4.7681e-02   valLoss:1.4068e-01  time: 1.44e+00\n",
      "epoch: 66   trainLoss: 4.9696e-02   valLoss:8.9271e-02  time: 1.46e+00\n",
      "epoch: 67   trainLoss: 4.7610e-02   valLoss:1.2755e-01  time: 1.43e+00\n",
      "epoch: 68   trainLoss: 4.0499e-02   valLoss:8.1393e-02  time: 1.43e+00\n",
      "epoch: 69   trainLoss: 3.3962e-02   valLoss:7.7814e-02  time: 1.43e+00\n",
      "epoch: 70   trainLoss: 3.4555e-02   valLoss:9.4020e-02  time: 1.44e+00\n",
      "epoch: 71   trainLoss: 3.7159e-02   valLoss:7.4925e-02  time: 1.43e+00\n",
      "epoch: 72   trainLoss: 4.4653e-02   valLoss:1.1596e-01  time: 1.42e+00\n",
      "epoch: 73   trainLoss: 5.5323e-02   valLoss:7.9911e-02  time: 1.42e+00\n",
      "epoch: 74   trainLoss: 5.4077e-02   valLoss:1.1872e-01  time: 1.41e+00\n",
      "epoch: 75   trainLoss: 6.2867e-02   valLoss:1.7729e-01  time: 1.44e+00\n",
      "epoch: 76   trainLoss: 6.1730e-02   valLoss:1.9120e-01  time: 1.44e+00\n",
      "epoch: 77   trainLoss: 7.1188e-02   valLoss:1.0449e-01  time: 1.43e+00\n",
      "epoch: 78   trainLoss: 5.2397e-02   valLoss:1.3214e-01  time: 1.42e+00\n",
      "epoch: 79   trainLoss: 4.3093e-02   valLoss:9.9356e-02  time: 1.44e+00\n",
      "epoch: 80   trainLoss: 4.1033e-02   valLoss:7.0624e-02  time: 1.44e+00\n",
      "epoch: 81   trainLoss: 3.2812e-02   valLoss:1.1291e-01  time: 1.46e+00\n",
      "epoch: 82   trainLoss: 4.0856e-02   valLoss:1.1991e-01  time: 1.44e+00\n",
      "epoch: 83   trainLoss: 3.6588e-02   valLoss:1.1429e-01  time: 1.46e+00\n",
      "epoch: 84   trainLoss: 3.5752e-02   valLoss:1.3014e-01  time: 1.44e+00\n",
      "epoch: 85   trainLoss: 2.9727e-02   valLoss:9.9769e-02  time: 1.43e+00\n",
      "epoch: 86   trainLoss: 2.7420e-02   valLoss:7.5801e-02  time: 1.45e+00\n",
      "epoch: 87   trainLoss: 3.3539e-02   valLoss:9.1629e-02  time: 1.45e+00\n",
      "epoch: 88   trainLoss: 3.4965e-02   valLoss:1.2881e-01  time: 1.44e+00\n",
      "epoch: 89   trainLoss: 3.3293e-02   valLoss:7.9444e-02  time: 1.44e+00\n",
      "epoch: 90   trainLoss: 4.2476e-02   valLoss:1.2911e-01  time: 1.43e+00\n",
      "epoch: 91   trainLoss: 5.0506e-02   valLoss:1.7531e-01  time: 1.46e+00\n",
      "epoch: 92   trainLoss: 4.9355e-02   valLoss:2.2285e-01  time: 1.44e+00\n",
      "epoch: 93   trainLoss: 5.4583e-02   valLoss:1.0622e-01  time: 1.42e+00\n",
      "epoch: 94   trainLoss: 4.2401e-02   valLoss:6.0187e-02  time: 1.43e+00\n",
      "epoch: 95   trainLoss: 5.5980e-02   valLoss:9.4296e-02  time: 1.44e+00\n",
      "epoch: 96   trainLoss: 4.9264e-02   valLoss:1.3326e-01  time: 1.44e+00\n",
      "epoch: 97   trainLoss: 5.1962e-02   valLoss:1.4069e-01  time: 1.43e+00\n",
      "epoch: 98   trainLoss: 5.6280e-02   valLoss:1.0962e-01  time: 1.43e+00\n",
      "epoch: 99   trainLoss: 4.4228e-02   valLoss:1.0382e-01  time: 1.45e+00\n",
      "loading checkpoint 94\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-3b69b98908914b84854d0d750939d9a4\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-3b69b98908914b84854d0d750939d9a4\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-3b69b98908914b84854d0d750939d9a4\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-85d6f519612ee20737deb5314000353d\"}, \"mark\": \"line\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"set\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"epoch\"}, {\"type\": \"quantitative\", \"field\": \"value\"}], \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"title\": \"loss\"}, \"field\": \"value\"}}, \"height\": 200, \"transform\": [{\"fold\": [\"train\", \"val\"], \"as\": [\"set\", \"value\"]}], \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-85d6f519612ee20737deb5314000353d\": [{\"train\": 0.9390578866004944, \"val\": 0.961076560533709, \"epoch\": 0}, {\"train\": 0.7793400684992472, \"val\": 0.9516804128264388, \"epoch\": 1}, {\"train\": 0.6441463033358256, \"val\": 0.97876693756768, \"epoch\": 2}, {\"train\": 0.5132220486799876, \"val\": 1.0714799633456602, \"epoch\": 3}, {\"train\": 0.4445239106814067, \"val\": 1.3035238808779805, \"epoch\": 4}, {\"train\": 0.39518338441848755, \"val\": 1.8738058846857812, \"epoch\": 5}, {\"train\": 0.3503721555074056, \"val\": 2.566841138181863, \"epoch\": 6}, {\"train\": 0.29780101776123047, \"val\": 2.6705308771795697, \"epoch\": 7}, {\"train\": 0.23463610808054605, \"val\": 1.4770833427707355, \"epoch\": 8}, {\"train\": 0.23480053742726645, \"val\": 0.5136044279982647, \"epoch\": 9}, {\"train\": 0.22997353474299112, \"val\": 0.3635103457296888, \"epoch\": 10}, {\"train\": 0.23080680767695108, \"val\": 0.4856779857849081, \"epoch\": 11}, {\"train\": 0.18156549831231436, \"val\": 0.5604127959382755, \"epoch\": 12}, {\"train\": 0.22462756435076395, \"val\": 0.33167796419864454, \"epoch\": 13}, {\"train\": 0.1811911960442861, \"val\": 1.5612841078459665, \"epoch\": 14}, {\"train\": 0.16214696566263834, \"val\": 1.677828730808364, \"epoch\": 15}, {\"train\": 0.1481731484333674, \"val\": 1.3534030188909836, \"epoch\": 16}, {\"train\": 0.13099757333596548, \"val\": 0.7954659102208637, \"epoch\": 17}, {\"train\": 0.13354005416234335, \"val\": 0.5906140097003016, \"epoch\": 18}, {\"train\": 0.1238468736410141, \"val\": 0.5412668673045657, \"epoch\": 19}, {\"train\": 0.1298969884713491, \"val\": 0.7364214020263817, \"epoch\": 20}, {\"train\": 0.14999904235204062, \"val\": 0.30243046385132605, \"epoch\": 21}, {\"train\": 0.10560604929924011, \"val\": 0.43462267188631276, \"epoch\": 22}, {\"train\": 0.0971994400024414, \"val\": 0.525736134344091, \"epoch\": 23}, {\"train\": 0.09667719652255376, \"val\": 0.3408487731659854, \"epoch\": 24}, {\"train\": 0.09084787716468175, \"val\": 0.21116006552000288, \"epoch\": 25}, {\"train\": 0.08103853712479274, \"val\": 0.2680396095470146, \"epoch\": 26}, {\"train\": 0.08358874668677647, \"val\": 0.18004909823476165, \"epoch\": 27}, {\"train\": 0.08950155476729076, \"val\": 0.1941836559455152, \"epoch\": 28}, {\"train\": 0.07269361987709999, \"val\": 0.2549162336745886, \"epoch\": 29}, {\"train\": 0.0807179460922877, \"val\": 0.20241344977963577, \"epoch\": 30}, {\"train\": 0.07289068400859833, \"val\": 0.1925673427672505, \"epoch\": 31}, {\"train\": 0.07011392340064049, \"val\": 0.2137697758109964, \"epoch\": 32}, {\"train\": 0.09960018843412399, \"val\": 0.1782812943544101, \"epoch\": 33}, {\"train\": 0.0724150650203228, \"val\": 0.16080622180985907, \"epoch\": 34}, {\"train\": 0.05534647901852926, \"val\": 0.24186964884952264, \"epoch\": 35}, {\"train\": 0.05782943467299143, \"val\": 0.12257385632040461, \"epoch\": 36}, {\"train\": 0.04887558271487554, \"val\": 0.19434122635155088, \"epoch\": 37}, {\"train\": 0.05478351190686226, \"val\": 0.16006710423432566, \"epoch\": 38}, {\"train\": 0.052000802010297775, \"val\": 0.13386579599507428, \"epoch\": 39}, {\"train\": 0.04315337290366491, \"val\": 0.14767819309296706, \"epoch\": 40}, {\"train\": 0.07004103188713391, \"val\": 0.1668027844193771, \"epoch\": 41}, {\"train\": 0.06782861674825351, \"val\": 0.17348435127900708, \"epoch\": 42}, {\"train\": 0.04481792449951172, \"val\": 0.1781995371070311, \"epoch\": 43}, {\"train\": 0.056940759221712746, \"val\": 0.25981108583854856, \"epoch\": 44}, {\"train\": 0.06122874220212301, \"val\": 0.1383165985311347, \"epoch\": 45}, {\"train\": 0.06399928654233615, \"val\": 0.13197439147970053, \"epoch\": 46}, {\"train\": 0.06575383121768634, \"val\": 0.10380928600810606, \"epoch\": 47}, {\"train\": 0.05598268906275431, \"val\": 0.20170691371377972, \"epoch\": 48}, {\"train\": 0.054550621658563614, \"val\": 0.1698284330346656, \"epoch\": 49}, {\"train\": 0.05893829713265101, \"val\": 0.2452314821701428, \"epoch\": 50}, {\"train\": 0.06467345853646596, \"val\": 0.12937589350190978, \"epoch\": 51}, {\"train\": 0.06074767435590426, \"val\": 0.31631527398712933, \"epoch\": 52}, {\"train\": 0.06777928645412128, \"val\": 0.13097013227848542, \"epoch\": 53}, {\"train\": 0.08314072092374165, \"val\": 0.1356557674869826, \"epoch\": 54}, {\"train\": 0.06443013126651446, \"val\": 0.1623985538241902, \"epoch\": 55}, {\"train\": 0.04633806645870209, \"val\": 0.10922898418546, \"epoch\": 56}, {\"train\": 0.05647547667225202, \"val\": 0.15945881409829277, \"epoch\": 57}, {\"train\": 0.058173192044099174, \"val\": 0.13092811715237243, \"epoch\": 58}, {\"train\": 0.05305630341172218, \"val\": 0.11896040551881823, \"epoch\": 59}, {\"train\": 0.048295767356952034, \"val\": 0.13771973175634802, \"epoch\": 60}, {\"train\": 0.044341716915369034, \"val\": 0.13378242082479927, \"epoch\": 61}, {\"train\": 0.06159263849258423, \"val\": 0.20836996264686738, \"epoch\": 62}, {\"train\": 0.07332386697332065, \"val\": 0.15277197935480485, \"epoch\": 63}, {\"train\": 0.047618318349123, \"val\": 0.15738447496012128, \"epoch\": 64}, {\"train\": 0.04768130804101626, \"val\": 0.14068463123058556, \"epoch\": 65}, {\"train\": 0.04969644546508789, \"val\": 0.08927073707605747, \"epoch\": 66}, {\"train\": 0.04760970175266266, \"val\": 0.12755193738956694, \"epoch\": 67}, {\"train\": 0.040498907367388405, \"val\": 0.08139287833883255, \"epoch\": 68}, {\"train\": 0.033961708967884384, \"val\": 0.07781402490002585, \"epoch\": 69}, {\"train\": 0.03455520669619242, \"val\": 0.09402011274532587, \"epoch\": 70}, {\"train\": 0.03715947084128857, \"val\": 0.0749254680467183, \"epoch\": 71}, {\"train\": 0.04465344424049059, \"val\": 0.11596461109756664, \"epoch\": 72}, {\"train\": 0.05532261605064074, \"val\": 0.0799110638477874, \"epoch\": 73}, {\"train\": 0.054077159613370895, \"val\": 0.11872100184619841, \"epoch\": 74}, {\"train\": 0.06286728257934253, \"val\": 0.1772929786109469, \"epoch\": 75}, {\"train\": 0.06172963231801987, \"val\": 0.19120013574138284, \"epoch\": 76}, {\"train\": 0.07118838901321094, \"val\": 0.1044886656929049, \"epoch\": 77}, {\"train\": 0.052396917094786964, \"val\": 0.13213634173196084, \"epoch\": 78}, {\"train\": 0.043092804650465645, \"val\": 0.0993555474905642, \"epoch\": 79}, {\"train\": 0.041033086677392326, \"val\": 0.0706235816361624, \"epoch\": 80}, {\"train\": 0.03281235756973425, \"val\": 0.11291110827328844, \"epoch\": 81}, {\"train\": 0.0408563818782568, \"val\": 0.11991483923823883, \"epoch\": 82}, {\"train\": 0.03658816839257876, \"val\": 0.11428897970149086, \"epoch\": 83}, {\"train\": 0.03575213501850764, \"val\": 0.13013844190518958, \"epoch\": 84}, {\"train\": 0.029726567367712658, \"val\": 0.09976884833304211, \"epoch\": 85}, {\"train\": 0.027420049533247948, \"val\": 0.07580106850946322, \"epoch\": 86}, {\"train\": 0.03353877613941828, \"val\": 0.09162889721294588, \"epoch\": 87}, {\"train\": 0.034964669495821, \"val\": 0.12880540482216962, \"epoch\": 88}, {\"train\": 0.03329322052498659, \"val\": 0.07944444263854099, \"epoch\": 89}, {\"train\": 0.04247585559884707, \"val\": 0.1291109181733595, \"epoch\": 90}, {\"train\": 0.050506451477607094, \"val\": 0.17531127179110492, \"epoch\": 91}, {\"train\": 0.049355398863554, \"val\": 0.22284693211420542, \"epoch\": 92}, {\"train\": 0.05458251138528188, \"val\": 0.1062246797136376, \"epoch\": 93}, {\"train\": 0.042401264111200966, \"val\": 0.06018714864061352, \"epoch\": 94}, {\"train\": 0.05597971628109614, \"val\": 0.09429551532526535, \"epoch\": 95}, {\"train\": 0.049264407406250633, \"val\": 0.13326205734025548, \"epoch\": 96}, {\"train\": 0.051961722473303475, \"val\": 0.1406935845863902, \"epoch\": 97}, {\"train\": 0.05628043909867605, \"val\": 0.10962428987302163, \"epoch\": 98}, {\"train\": 0.04422760630647341, \"val\": 0.10381690981254603, \"epoch\": 99}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn = FeaStNet()\n",
    "history = gcn.trainModel(trainData, valData, \n",
    "                         epochs=100,\n",
    "                         saveDir='results/gcn01/')\n",
    "\n",
    "plotHistory(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mre</th>\n",
       "      <th>peakR2</th>\n",
       "      <th>maxAggR2</th>\n",
       "      <th>meanAggR2</th>\n",
       "      <th>minAggR2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.074794</td>\n",
       "      <td>0.917876</td>\n",
       "      <td>0.972318</td>\n",
       "      <td>0.843597</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.083019</td>\n",
       "      <td>0.821941</td>\n",
       "      <td>0.938668</td>\n",
       "      <td>0.807591</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mse       mae       mre    peakR2  maxAggR2  meanAggR2  minAggR2\n",
       "train  0.000005  0.001412  0.074794  0.917876  0.972318   0.843597       0.0\n",
       "test   0.000007  0.001558  0.083019  0.821941  0.938668   0.807591       0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainRes = gcn.testModel(trainData)\n",
    "testRes = gcn.testModel(testData)\n",
    "pd.DataFrame([trainRes, testRes], index=['train', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'height' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0928d77b01d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplotTruss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshowDeformed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefScale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/home/ewhalen/projects/gcnSurrogate/gcnSurrogate/visualization/altTrussViz.py\u001b[0m in \u001b[0;36mplotTruss\u001b[0;34m(graph, showDeformed, defScale, showUndeformed, prediction, baseColor, fadedColor, brightColor, width, z, domX, domY, lineWidth, lineOpacity, showPoints, pointSize, withoutConfigure, background)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfPoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdomX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdomX\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'auto'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdomX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdomY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdomY\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'auto'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdomY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mrangeX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdomX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdomX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mrangeY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdomY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdomY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'height' referenced before assignment"
     ]
    }
   ],
   "source": [
    "i = 4\n",
    "pred = gcn.predict([testData[i]])[0]\n",
    "plotTruss(testData[i], showDeformed=True, defScale=20, prediction=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive scatter plot\n",
    "alt.data_transformers.enable('json')\n",
    "allPreds = gcn.predict(testData)\n",
    "display(interactiveErrorPlot(testData, allPreds))\n",
    "alt.data_transformers.enable('default');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptgeom",
   "language": "python",
   "name": "ptgeom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
