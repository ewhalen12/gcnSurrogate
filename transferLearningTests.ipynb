{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning tests\n",
    "Eamon Whalen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "from gcnSurrogate.models.feastnetSurrogateModel import FeaStNet\n",
    "from gcnSurrogate.models.pointRegressorSurrogateModel import PointRegressor\n",
    "from gcnSurrogate.readers.loadConmechGraphs import loadConmechGraphs\n",
    "from gcnSurrogate.visualization.altTrussViz import plotTruss, interactiveErrorPlot\n",
    "from gcnSurrogate.util.gcnSurrogateUtil import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.137562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.740254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.004530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.010635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.016778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.032392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.419552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             maxes\n",
       "count  1000.000000\n",
       "mean      0.137562\n",
       "std       1.740254\n",
       "min       0.004530\n",
       "25%       0.010635\n",
       "50%       0.016778\n",
       "75%       0.032392\n",
       "max      46.419552"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDir = \"data/2D_Truss_v1.3/conmech/\"\n",
    "testDir = os.path.join(dataDir, 'design_7_N_1000/')\n",
    "allGraphsUnfiltered = loadConmechGraphs(testDir)\n",
    "\n",
    "# dataDir = \"data/endLoadsv1.0/conmech/\"\n",
    "# testDir = os.path.join(dataDir, 'design_7_N_1000/')\n",
    "# allGraphsUnfiltered = loadConmechGraphs(testDir)\n",
    "\n",
    "maxes = [max(np.abs(graph.y.numpy().flatten())) for graph in allGraphsUnfiltered]\n",
    "source = pd.DataFrame(maxes, columns=['maxes'])\n",
    "source.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.019962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.013149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.004530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.010309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.014975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.026453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.067472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            maxes\n",
       "count  900.000000\n",
       "mean     0.019962\n",
       "std      0.013149\n",
       "min      0.004530\n",
       "25%      0.010309\n",
       "50%      0.014975\n",
       "75%      0.026453\n",
       "max      0.067472"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData = filterbyDisp(allGraphsUnfiltered, 0.9)\n",
    "maxes = [max(np.abs(graph.y.numpy().flatten())) for graph in testData]\n",
    "source = pd.DataFrame(maxes, columns=['maxes'])\n",
    "maxDispCutoff = source.max().item()\n",
    "source.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load pre-train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrainFiles = glob.glob(os.path.join(dataDir, '*1000.csv'))\n",
    "# pretrainFiles.remove(testFile)\n",
    "\n",
    "# allPretrainGraphs = []\n",
    "# for pretrainFile in pretrainFiles:\n",
    "#     designName = pretrainDir.split('/')[-1].split('_N')[0]\n",
    "#     print(f'loading {designName}')\n",
    "#     graphsUnfiltered = loadGhGraphs(pretrainFile, NUM_DV=5)\n",
    "#     graphs = filterbyDisp(graphsUnfiltered, 0.9)\n",
    "#     allPretrainGraphs.extend(graphs)\n",
    "\n",
    "# print(f'loaded {len(allPretrainGraphs)} pretraining graphs')\n",
    "# pretrainData, pretrainValData, _ = partitionGraphList(allPretrainGraphs, testSize=0.0, valSize=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from data/2D_Truss_v1.3/conmech/design_5_N_1000/\n",
      "loading from data/2D_Truss_v1.3/conmech/design_9_N_1000/\n",
      "loading from data/2D_Truss_v1.3/conmech/design_6_N_1000/\n",
      "loading from data/2D_Truss_v1.3/conmech/design_8_N_1000/\n",
      "loaded 3600 pretraining graphs\n"
     ]
    }
   ],
   "source": [
    "# pretrainDirs = glob.glob('data/2D_Truss_v1.3/conmech/design_7_N_1000*/')\n",
    "\n",
    "pretrainDirs = glob.glob(os.path.join(dataDir, '*1000/'))\n",
    "pretrainDirs.remove(testDir)\n",
    "\n",
    "allPretrainGraphs = []\n",
    "for pretrainDir in pretrainDirs:\n",
    "    designName = pretrainDir.split('/')[-2].split('_N')[0]\n",
    "    print(f'loading from {pretrainDir}')\n",
    "    graphsUnfiltered = loadConmechGraphs(pretrainDir)\n",
    "    graphs = filterbyDisp(graphsUnfiltered, 0.9)\n",
    "    allPretrainGraphs.extend(graphs)\n",
    "\n",
    "print(f'loaded {len(allPretrainGraphs)} pretraining graphs')\n",
    "pretrainData, pretrainValData, _ = partitionGraphList(allPretrainGraphs, testSize=0.0, valSize=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0   trainLoss: 6.1295e-01   valLoss:9.3772e-01  time: 7.52e+00\n",
      "epoch: 1   trainLoss: 3.1781e-01   valLoss:9.1007e-01  time: 7.26e+00\n",
      "epoch: 2   trainLoss: 2.2988e-01   valLoss:8.8655e-01  time: 7.32e+00\n",
      "epoch: 3   trainLoss: 1.7370e-01   valLoss:7.8663e-01  time: 7.33e+00\n",
      "epoch: 4   trainLoss: 1.3490e-01   valLoss:5.0874e-01  time: 7.31e+00\n",
      "epoch: 5   trainLoss: 1.3702e-01   valLoss:3.9200e-01  time: 7.32e+00\n",
      "epoch: 6   trainLoss: 1.1931e-01   valLoss:9.4201e-01  time: 7.35e+00\n",
      "epoch: 7   trainLoss: 1.1081e-01   valLoss:2.5473e-01  time: 7.32e+00\n",
      "epoch: 8   trainLoss: 1.0649e-01   valLoss:4.6683e-01  time: 7.37e+00\n",
      "epoch: 9   trainLoss: 1.0172e-01   valLoss:4.2352e-01  time: 7.39e+00\n",
      "epoch: 10   trainLoss: 9.7128e-02   valLoss:9.4138e-02  time: 7.39e+00\n",
      "epoch: 11   trainLoss: 7.7486e-02   valLoss:1.0351e-01  time: 7.37e+00\n",
      "epoch: 12   trainLoss: 7.1469e-02   valLoss:8.4263e-02  time: 7.42e+00\n",
      "epoch: 13   trainLoss: 6.3856e-02   valLoss:9.4483e-02  time: 7.38e+00\n",
      "epoch: 14   trainLoss: 6.2559e-02   valLoss:1.5697e-01  time: 8.18e+00\n",
      "epoch: 15   trainLoss: 8.6298e-02   valLoss:8.1795e-02  time: 7.57e+00\n",
      "epoch: 16   trainLoss: 8.1800e-02   valLoss:1.3840e-01  time: 8.21e+00\n",
      "epoch: 17   trainLoss: 7.1716e-02   valLoss:6.0755e-02  time: 7.75e+00\n",
      "epoch: 18   trainLoss: 6.7985e-02   valLoss:6.9246e-02  time: 8.22e+00\n",
      "epoch: 19   trainLoss: 7.4681e-02   valLoss:8.3547e-02  time: 8.10e+00\n",
      "epoch: 20   trainLoss: 6.8024e-02   valLoss:1.8112e-01  time: 8.16e+00\n",
      "epoch: 21   trainLoss: 5.5087e-02   valLoss:8.6825e-02  time: 8.17e+00\n",
      "epoch: 22   trainLoss: 7.3003e-02   valLoss:1.0273e-01  time: 7.52e+00\n",
      "epoch: 23   trainLoss: 6.5145e-02   valLoss:4.4947e-02  time: 7.76e+00\n",
      "epoch: 24   trainLoss: 6.3923e-02   valLoss:3.8600e-01  time: 7.78e+00\n",
      "epoch: 25   trainLoss: 5.6999e-02   valLoss:1.1194e-01  time: 7.44e+00\n",
      "epoch: 26   trainLoss: 6.1314e-02   valLoss:1.2762e-01  time: 7.45e+00\n",
      "epoch: 27   trainLoss: 5.5914e-02   valLoss:1.6547e-01  time: 7.35e+00\n",
      "epoch: 28   trainLoss: 6.1236e-02   valLoss:6.8745e-02  time: 7.26e+00\n",
      "epoch: 29   trainLoss: 6.0090e-02   valLoss:2.1838e-01  time: 7.23e+00\n",
      "epoch: 30   trainLoss: 6.0204e-02   valLoss:7.4036e-02  time: 7.19e+00\n",
      "epoch: 31   trainLoss: 5.2509e-02   valLoss:4.9723e-02  time: 7.17e+00\n",
      "epoch: 32   trainLoss: 4.2559e-02   valLoss:5.2714e-02  time: 7.22e+00\n",
      "epoch: 33   trainLoss: 6.3938e-02   valLoss:5.9107e-02  time: 7.16e+00\n",
      "epoch: 34   trainLoss: 4.9647e-02   valLoss:2.5648e-01  time: 7.19e+00\n",
      "epoch: 35   trainLoss: 4.8300e-02   valLoss:4.2015e-02  time: 7.16e+00\n",
      "epoch: 36   trainLoss: 5.0080e-02   valLoss:1.1787e-01  time: 7.18e+00\n",
      "epoch: 37   trainLoss: 4.9058e-02   valLoss:5.5355e-02  time: 7.14e+00\n",
      "epoch: 38   trainLoss: 5.3607e-02   valLoss:5.9605e-02  time: 7.19e+00\n",
      "epoch: 39   trainLoss: 5.6492e-02   valLoss:5.6137e-02  time: 7.23e+00\n",
      "epoch: 40   trainLoss: 5.2351e-02   valLoss:5.1306e-02  time: 7.17e+00\n",
      "epoch: 41   trainLoss: 4.7985e-02   valLoss:1.0575e-01  time: 7.24e+00\n",
      "epoch: 42   trainLoss: 4.9133e-02   valLoss:4.8271e-02  time: 7.18e+00\n",
      "epoch: 43   trainLoss: 4.7912e-02   valLoss:7.9866e-02  time: 7.19e+00\n",
      "epoch: 44   trainLoss: 5.0934e-02   valLoss:5.1197e-02  time: 7.19e+00\n",
      "epoch: 45   trainLoss: 4.7532e-02   valLoss:4.8057e-02  time: 7.20e+00\n",
      "epoch: 46   trainLoss: 4.4252e-02   valLoss:6.8429e-02  time: 7.23e+00\n",
      "epoch: 47   trainLoss: 5.1702e-02   valLoss:5.0310e-02  time: 7.17e+00\n",
      "epoch: 48   trainLoss: 4.4300e-02   valLoss:7.8843e-02  time: 7.16e+00\n",
      "epoch: 49   trainLoss: 4.6767e-02   valLoss:5.8577e-02  time: 7.18e+00\n",
      "epoch: 50   trainLoss: 4.3017e-02   valLoss:6.0391e-02  time: 7.18e+00\n",
      "epoch: 51   trainLoss: 4.5513e-02   valLoss:8.3059e-02  time: 7.36e+00\n",
      "epoch: 52   trainLoss: 4.1836e-02   valLoss:6.1704e-02  time: 7.43e+00\n",
      "epoch: 53   trainLoss: 5.1885e-02   valLoss:6.3896e-02  time: 7.54e+00\n",
      "epoch: 54   trainLoss: 5.7459e-02   valLoss:9.3535e-02  time: 7.25e+00\n",
      "epoch: 55   trainLoss: 5.4455e-02   valLoss:1.8648e-01  time: 7.24e+00\n",
      "epoch: 56   trainLoss: 4.6525e-02   valLoss:4.6313e-02  time: 7.20e+00\n",
      "epoch: 57   trainLoss: 4.9988e-02   valLoss:5.1083e-02  time: 7.24e+00\n",
      "epoch: 58   trainLoss: 4.2675e-02   valLoss:8.5666e-02  time: 7.19e+00\n",
      "epoch: 59   trainLoss: 4.2288e-02   valLoss:5.1623e-02  time: 7.20e+00\n",
      "epoch: 60   trainLoss: 4.4621e-02   valLoss:7.9799e-02  time: 7.36e+00\n",
      "epoch: 61   trainLoss: 4.4410e-02   valLoss:6.3123e-02  time: 7.19e+00\n",
      "epoch: 62   trainLoss: 4.4504e-02   valLoss:3.3613e-02  time: 7.13e+00\n",
      "epoch: 63   trainLoss: 4.3736e-02   valLoss:1.0559e-01  time: 7.20e+00\n",
      "epoch: 64   trainLoss: 4.0308e-02   valLoss:4.5962e-02  time: 7.10e+00\n",
      "epoch: 65   trainLoss: 3.8463e-02   valLoss:6.5007e-02  time: 7.17e+00\n",
      "epoch: 66   trainLoss: 4.3039e-02   valLoss:4.8299e-02  time: 7.16e+00\n",
      "epoch: 67   trainLoss: 4.5204e-02   valLoss:3.6104e-02  time: 7.24e+00\n",
      "epoch: 68   trainLoss: 4.4807e-02   valLoss:1.5737e-01  time: 7.07e+00\n",
      "epoch: 69   trainLoss: 4.2654e-02   valLoss:6.7659e-02  time: 7.06e+00\n",
      "epoch: 70   trainLoss: 4.1721e-02   valLoss:4.0026e-02  time: 7.10e+00\n",
      "epoch: 71   trainLoss: 3.1377e-02   valLoss:3.7594e-02  time: 7.07e+00\n",
      "epoch: 72   trainLoss: 3.9131e-02   valLoss:5.6866e-02  time: 7.08e+00\n",
      "epoch: 73   trainLoss: 3.7811e-02   valLoss:3.1635e-02  time: 7.15e+00\n",
      "epoch: 74   trainLoss: 4.3022e-02   valLoss:4.5317e-02  time: 7.16e+00\n",
      "epoch: 75   trainLoss: 4.4108e-02   valLoss:7.0444e-02  time: 7.05e+00\n",
      "epoch: 76   trainLoss: 4.7738e-02   valLoss:6.6014e-02  time: 7.19e+00\n",
      "epoch: 77   trainLoss: 4.8420e-02   valLoss:1.9447e-01  time: 7.21e+00\n",
      "epoch: 78   trainLoss: 5.1950e-02   valLoss:6.7681e-02  time: 7.24e+00\n",
      "epoch: 79   trainLoss: 5.1415e-02   valLoss:8.9731e-02  time: 7.22e+00\n",
      "epoch: 80   trainLoss: 4.4801e-02   valLoss:4.9159e-02  time: 7.17e+00\n",
      "epoch: 81   trainLoss: 4.7438e-02   valLoss:8.2921e-02  time: 7.26e+00\n",
      "epoch: 82   trainLoss: 5.3402e-02   valLoss:6.0773e-02  time: 7.13e+00\n",
      "epoch: 83   trainLoss: 4.2454e-02   valLoss:2.5816e-01  time: 7.12e+00\n",
      "epoch: 84   trainLoss: 6.2226e-02   valLoss:1.0391e-01  time: 7.56e+00\n",
      "epoch: 85   trainLoss: 5.3920e-02   valLoss:9.2020e-02  time: 7.99e+00\n",
      "epoch: 86   trainLoss: 3.9615e-02   valLoss:2.7885e-02  time: 8.02e+00\n",
      "epoch: 87   trainLoss: 3.5814e-02   valLoss:3.3044e-02  time: 8.08e+00\n",
      "epoch: 88   trainLoss: 3.8573e-02   valLoss:4.9844e-02  time: 8.02e+00\n",
      "epoch: 89   trainLoss: 4.0393e-02   valLoss:4.6171e-02  time: 8.03e+00\n",
      "epoch: 90   trainLoss: 4.1976e-02   valLoss:7.5381e-02  time: 7.97e+00\n",
      "epoch: 91   trainLoss: 3.6272e-02   valLoss:5.7028e-02  time: 7.95e+00\n",
      "epoch: 92   trainLoss: 3.5200e-02   valLoss:4.5117e-02  time: 7.84e+00\n",
      "epoch: 93   trainLoss: 3.9089e-02   valLoss:6.6816e-02  time: 7.85e+00\n",
      "epoch: 94   trainLoss: 5.3140e-02   valLoss:6.0831e-02  time: 7.53e+00\n",
      "epoch: 95   trainLoss: 4.5118e-02   valLoss:6.4789e-02  time: 7.48e+00\n",
      "epoch: 96   trainLoss: 3.5768e-02   valLoss:7.0585e-02  time: 7.99e+00\n",
      "epoch: 97   trainLoss: 3.2942e-02   valLoss:9.7575e-02  time: 7.88e+00\n",
      "epoch: 98   trainLoss: 4.5838e-02   valLoss:4.2993e-02  time: 7.83e+00\n",
      "epoch: 99   trainLoss: 4.1367e-02   valLoss:3.5022e-02  time: 7.68e+00\n",
      "loading checkpoint 86\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-02ca1ceb08994a11ac07f22e086fba2a\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-02ca1ceb08994a11ac07f22e086fba2a\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-02ca1ceb08994a11ac07f22e086fba2a\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-c3a3bcf0f8b315cb3adf31f4b2199487\"}, \"mark\": \"line\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"set\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"epoch\"}, {\"type\": \"quantitative\", \"field\": \"value\"}], \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"title\": \"loss\"}, \"field\": \"value\"}}, \"height\": 200, \"transform\": [{\"fold\": [\"train\", \"val\"], \"as\": [\"set\", \"value\"]}], \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-c3a3bcf0f8b315cb3adf31f4b2199487\": [{\"train\": 0.6129533077279726, \"val\": 0.9377216854995047, \"epoch\": 0}, {\"train\": 0.31780511264999706, \"val\": 0.9100697766575548, \"epoch\": 1}, {\"train\": 0.22988499452670416, \"val\": 0.8865527145978477, \"epoch\": 2}, {\"train\": 0.173702759668231, \"val\": 0.7866261355596146, \"epoch\": 3}, {\"train\": 0.13489506455759206, \"val\": 0.5087426688280646, \"epoch\": 4}, {\"train\": 0.1370210045327743, \"val\": 0.39200199817617737, \"epoch\": 5}, {\"train\": 0.11930790543556213, \"val\": 0.9420093246356205, \"epoch\": 6}, {\"train\": 0.11081471294164658, \"val\": 0.2547261013313093, \"epoch\": 7}, {\"train\": 0.10649378908177216, \"val\": 0.4668321571588792, \"epoch\": 8}, {\"train\": 0.10172030702233315, \"val\": 0.4235151163543816, \"epoch\": 9}, {\"train\": 0.09712769649922848, \"val\": 0.0941377343208943, \"epoch\": 10}, {\"train\": 0.07748615648597479, \"val\": 0.10350785536381106, \"epoch\": 11}, {\"train\": 0.07146932557225227, \"val\": 0.08426266563797577, \"epoch\": 12}, {\"train\": 0.06385627451042335, \"val\": 0.09448297152347448, \"epoch\": 13}, {\"train\": 0.06255919051667054, \"val\": 0.15697113535608406, \"epoch\": 14}, {\"train\": 0.08629844710230827, \"val\": 0.0817949234145797, \"epoch\": 15}, {\"train\": 0.08179969557871421, \"val\": 0.1383952404855302, \"epoch\": 16}, {\"train\": 0.07171645263830821, \"val\": 0.060755256538848494, \"epoch\": 17}, {\"train\": 0.06798504944890738, \"val\": 0.06924642688180838, \"epoch\": 18}, {\"train\": 0.074680522394677, \"val\": 0.08354747823129098, \"epoch\": 19}, {\"train\": 0.06802430345366399, \"val\": 0.18112213190481136, \"epoch\": 20}, {\"train\": 0.055087268042067684, \"val\": 0.08682529858865395, \"epoch\": 21}, {\"train\": 0.07300255230317514, \"val\": 0.10273491458975952, \"epoch\": 22}, {\"train\": 0.06514526872585218, \"val\": 0.044946570680218026, \"epoch\": 23}, {\"train\": 0.06392347409079473, \"val\": 0.3859963046964603, \"epoch\": 24}, {\"train\": 0.05699877720326185, \"val\": 0.11193627108522276, \"epoch\": 25}, {\"train\": 0.0613142525156339, \"val\": 0.1276172859016461, \"epoch\": 26}, {\"train\": 0.05591401613006989, \"val\": 0.1654677098586776, \"epoch\": 27}, {\"train\": 0.0612357376764218, \"val\": 0.06874450093816482, \"epoch\": 28}, {\"train\": 0.0600896617397666, \"val\": 0.21838283535541483, \"epoch\": 29}, {\"train\": 0.06020379904657602, \"val\": 0.07403560203426794, \"epoch\": 30}, {\"train\": 0.052508631410698094, \"val\": 0.04972325401915306, \"epoch\": 31}, {\"train\": 0.0425589393513898, \"val\": 0.05271364509460033, \"epoch\": 32}, {\"train\": 0.0639384404445688, \"val\": 0.059107366153383974, \"epoch\": 33}, {\"train\": 0.04964735824614763, \"val\": 0.2564839144621079, \"epoch\": 34}, {\"train\": 0.04829969474424919, \"val\": 0.04201505285476472, \"epoch\": 35}, {\"train\": 0.05008004776512583, \"val\": 0.11787360559252125, \"epoch\": 36}, {\"train\": 0.04905785589168469, \"val\": 0.05535460857963362, \"epoch\": 37}, {\"train\": 0.05360714718699455, \"val\": 0.05960527203300175, \"epoch\": 38}, {\"train\": 0.05649168851474921, \"val\": 0.056136504313434234, \"epoch\": 39}, {\"train\": 0.05235148034989834, \"val\": 0.05130583762786248, \"epoch\": 40}, {\"train\": 0.047984534253676735, \"val\": 0.10575404724071699, \"epoch\": 41}, {\"train\": 0.049133178467551865, \"val\": 0.048270784081197, \"epoch\": 42}, {\"train\": 0.047911636686573424, \"val\": 0.07986649139633367, \"epoch\": 43}, {\"train\": 0.05093417161454757, \"val\": 0.051196714789666996, \"epoch\": 44}, {\"train\": 0.04753166219840447, \"val\": 0.04805671518832376, \"epoch\": 45}, {\"train\": 0.044252017668137945, \"val\": 0.06842862164377476, \"epoch\": 46}, {\"train\": 0.05170156775663296, \"val\": 0.050310441259406855, \"epoch\": 47}, {\"train\": 0.044299665838479996, \"val\": 0.07884325280212108, \"epoch\": 48}, {\"train\": 0.0467666449646155, \"val\": 0.05857679882039385, \"epoch\": 49}, {\"train\": 0.04301736752192179, \"val\": 0.06039076031237427, \"epoch\": 50}, {\"train\": 0.045513124826053776, \"val\": 0.08305921670032182, \"epoch\": 51}, {\"train\": 0.04183616256341338, \"val\": 0.061704231266156526, \"epoch\": 52}, {\"train\": 0.051885294107099376, \"val\": 0.06389632209104969, \"epoch\": 53}, {\"train\": 0.05745908680061499, \"val\": 0.09353517353388101, \"epoch\": 54}, {\"train\": 0.054454982901612915, \"val\": 0.18647695125072022, \"epoch\": 55}, {\"train\": 0.04652456225206455, \"val\": 0.04631313949627198, \"epoch\": 56}, {\"train\": 0.04998782183974981, \"val\": 0.05108277284070263, \"epoch\": 57}, {\"train\": 0.0426745256409049, \"val\": 0.08566565141426745, \"epoch\": 58}, {\"train\": 0.042287584859877825, \"val\": 0.05162259076001916, \"epoch\": 59}, {\"train\": 0.0446214002246658, \"val\": 0.07979898971000997, \"epoch\": 60}, {\"train\": 0.04441014708330234, \"val\": 0.06312341552456255, \"epoch\": 61}, {\"train\": 0.0445037546257178, \"val\": 0.03361285069474468, \"epoch\": 62}, {\"train\": 0.04373593985413512, \"val\": 0.10558947083320365, \"epoch\": 63}, {\"train\": 0.04030835364634792, \"val\": 0.04596196014253009, \"epoch\": 64}, {\"train\": 0.03846348558242122, \"val\": 0.06500710062779641, \"epoch\": 65}, {\"train\": 0.04303878856201967, \"val\": 0.04829875388300193, \"epoch\": 66}, {\"train\": 0.04520413869371017, \"val\": 0.036103697890131216, \"epoch\": 67}, {\"train\": 0.04480730354165038, \"val\": 0.1573657641887958, \"epoch\": 68}, {\"train\": 0.0426543178036809, \"val\": 0.06765896286901639, \"epoch\": 69}, {\"train\": 0.04172138481711348, \"val\": 0.04002614374513979, \"epoch\": 70}, {\"train\": 0.03137650294229388, \"val\": 0.037593606132496564, \"epoch\": 71}, {\"train\": 0.039131390396505594, \"val\": 0.056865938596806866, \"epoch\": 72}, {\"train\": 0.03781114766995112, \"val\": 0.03163452709376105, \"epoch\": 73}, {\"train\": 0.04302154807373881, \"val\": 0.045316575659887386, \"epoch\": 74}, {\"train\": 0.04410763860990604, \"val\": 0.07044373614092668, \"epoch\": 75}, {\"train\": 0.047738216196497284, \"val\": 0.06601354569278622, \"epoch\": 76}, {\"train\": 0.04841982200741768, \"val\": 0.19446792488581396, \"epoch\": 77}, {\"train\": 0.05195006945480903, \"val\": 0.0676806300244708, \"epoch\": 78}, {\"train\": 0.05141478776931763, \"val\": 0.08973066959814686, \"epoch\": 79}, {\"train\": 0.044801424723118544, \"val\": 0.049158593106161184, \"epoch\": 80}, {\"train\": 0.0474375548462073, \"val\": 0.0829213010966433, \"epoch\": 81}, {\"train\": 0.05340155431379875, \"val\": 0.0607732584208457, \"epoch\": 82}, {\"train\": 0.04245397153620919, \"val\": 0.2581590317799796, \"epoch\": 83}, {\"train\": 0.06222599744796753, \"val\": 0.1039086587295902, \"epoch\": 84}, {\"train\": 0.05392020413031181, \"val\": 0.09201998949973603, \"epoch\": 85}, {\"train\": 0.03961453136677543, \"val\": 0.027885052859050186, \"epoch\": 86}, {\"train\": 0.035814236383885145, \"val\": 0.03304378313079252, \"epoch\": 87}, {\"train\": 0.03857330931350589, \"val\": 0.049843632825326896, \"epoch\": 88}, {\"train\": 0.04039342453082403, \"val\": 0.04617060616556382, \"epoch\": 89}, {\"train\": 0.04197634973873695, \"val\": 0.07538092467627765, \"epoch\": 90}, {\"train\": 0.036272213173409305, \"val\": 0.05702767331601569, \"epoch\": 91}, {\"train\": 0.03520007307330767, \"val\": 0.045116654870367645, \"epoch\": 92}, {\"train\": 0.03908859705552459, \"val\": 0.06681615307687834, \"epoch\": 93}, {\"train\": 0.0531402767325441, \"val\": 0.06083082259369635, \"epoch\": 94}, {\"train\": 0.04511830396950245, \"val\": 0.0647885515309301, \"epoch\": 95}, {\"train\": 0.035767914882550635, \"val\": 0.07058527427186534, \"epoch\": 96}, {\"train\": 0.032942283898591995, \"val\": 0.09757530864714041, \"epoch\": 97}, {\"train\": 0.04583781585097313, \"val\": 0.04299337015362215, \"epoch\": 98}, {\"train\": 0.04136713749418656, \"val\": 0.03502164517067959, \"epoch\": 99}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saveDir = 'results/transferLrn_endloads_des7_02/'\n",
    "epochs = 100\n",
    "ptrGcn = FeaStNet()\n",
    "history = ptrGcn.trainModel(pretrainData, pretrainValData, \n",
    "                            epochs=epochs,\n",
    "                            saveDir=saveDir+f'preTrain/gcn/')\n",
    "\n",
    "ptrGcnCheckptFile = ptrGcn.checkptFile\n",
    "plotHistory(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mre</th>\n",
       "      <th>peakR2</th>\n",
       "      <th>maxAggR2</th>\n",
       "      <th>meanAggR2</th>\n",
       "      <th>minAggR2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.088008</td>\n",
       "      <td>0.950579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.108124</td>\n",
       "      <td>0.753640</td>\n",
       "      <td>0.926665</td>\n",
       "      <td>0.733292</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mse       mae       mre    peakR2  maxAggR2  meanAggR2  minAggR2\n",
       "train  0.000010  0.002060  0.088008  0.950579       NaN        NaN       NaN\n",
       "test   0.000013  0.002141  0.108124  0.753640  0.926665   0.733292       0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainRes = ptrGcn.testModel(pretrainData)\n",
    "testRes = ptrGcn.testModel(testData) # unseen topology\n",
    "pd.DataFrame([trainRes, testRes], index=['train', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transfer learning study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded train set of size 906\n",
      "epoch: 0   trainLoss: 8.6256e-01   valLoss:9.7420e-01  time: 8.65e+00\n",
      "epoch: 1   trainLoss: 5.5629e-01   valLoss:9.5715e-01  time: 8.56e+00\n",
      "epoch: 2   trainLoss: 4.3446e-01   valLoss:9.9647e-01  time: 7.51e+00\n",
      "epoch: 3   trainLoss: 3.4789e-01   valLoss:1.1202e+00  time: 7.49e+00\n",
      "epoch: 4   trainLoss: 3.1290e-01   valLoss:1.5436e+00  time: 7.52e+00\n",
      "epoch: 5   trainLoss: 2.5940e-01   valLoss:1.6812e+00  time: 7.50e+00\n",
      "epoch: 6   trainLoss: 2.3346e-01   valLoss:1.5650e+00  time: 7.54e+00\n",
      "epoch: 7   trainLoss: 1.9703e-01   valLoss:1.5522e+00  time: 7.48e+00\n",
      "epoch: 8   trainLoss: 1.9114e-01   valLoss:3.6080e+00  time: 7.52e+00\n",
      "epoch: 9   trainLoss: 1.9495e-01   valLoss:1.4038e+00  time: 7.54e+00\n",
      "epoch: 10   trainLoss: 1.7740e-01   valLoss:1.4875e+00  time: 7.47e+00\n",
      "epoch: 11   trainLoss: 1.6014e-01   valLoss:1.4211e+00  time: 7.48e+00\n",
      "epoch: 12   trainLoss: 1.4489e-01   valLoss:1.2753e+00  time: 7.52e+00\n",
      "epoch: 13   trainLoss: 1.3787e-01   valLoss:1.6779e+00  time: 7.50e+00\n",
      "epoch: 14   trainLoss: 1.2162e-01   valLoss:1.6069e+00  time: 7.53e+00\n",
      "epoch: 15   trainLoss: 1.3658e-01   valLoss:1.5460e+00  time: 7.48e+00\n",
      "epoch: 16   trainLoss: 1.1305e-01   valLoss:1.6169e+00  time: 8.01e+00\n",
      "epoch: 17   trainLoss: 1.1216e-01   valLoss:2.3109e+00  time: 8.48e+00\n",
      "epoch: 18   trainLoss: 1.1072e-01   valLoss:2.2910e+00  time: 8.01e+00\n",
      "epoch: 19   trainLoss: 9.5874e-02   valLoss:1.0874e+00  time: 8.16e+00\n",
      "epoch: 20   trainLoss: 1.1609e-01   valLoss:2.7767e+00  time: 7.50e+00\n",
      "epoch: 21   trainLoss: 1.0874e-01   valLoss:1.1534e+00  time: 7.45e+00\n",
      "epoch: 22   trainLoss: 1.0451e-01   valLoss:2.9753e+00  time: 7.36e+00\n",
      "epoch: 23   trainLoss: 9.7243e-02   valLoss:1.7373e+00  time: 7.33e+00\n",
      "epoch: 24   trainLoss: 8.4199e-02   valLoss:1.9489e+00  time: 7.42e+00\n",
      "epoch: 25   trainLoss: 8.0353e-02   valLoss:1.4219e+00  time: 7.44e+00\n",
      "epoch: 26   trainLoss: 9.0926e-02   valLoss:1.0958e+00  time: 7.47e+00\n",
      "epoch: 27   trainLoss: 7.9615e-02   valLoss:1.5853e+00  time: 7.49e+00\n",
      "epoch: 28   trainLoss: 7.9932e-02   valLoss:1.5610e+00  time: 7.38e+00\n",
      "epoch: 29   trainLoss: 9.1211e-02   valLoss:1.4762e+00  time: 7.46e+00\n",
      "epoch: 30   trainLoss: 9.0545e-02   valLoss:1.5574e+00  time: 7.41e+00\n",
      "epoch: 31   trainLoss: 7.2840e-02   valLoss:9.1404e-01  time: 7.41e+00\n",
      "epoch: 32   trainLoss: 5.9171e-02   valLoss:7.9345e-01  time: 7.47e+00\n",
      "epoch: 33   trainLoss: 8.5746e-02   valLoss:2.0713e+00  time: 7.33e+00\n",
      "epoch: 34   trainLoss: 8.1133e-02   valLoss:9.9836e-01  time: 7.37e+00\n",
      "epoch: 35   trainLoss: 6.8184e-02   valLoss:4.8208e-01  time: 7.36e+00\n",
      "epoch: 36   trainLoss: 7.3281e-02   valLoss:6.5242e-01  time: 7.40e+00\n",
      "epoch: 37   trainLoss: 7.7673e-02   valLoss:1.3626e+00  time: 7.37e+00\n",
      "epoch: 38   trainLoss: 7.5076e-02   valLoss:1.1704e+00  time: 7.40e+00\n",
      "epoch: 39   trainLoss: 7.2128e-02   valLoss:5.0853e-01  time: 7.48e+00\n",
      "epoch: 40   trainLoss: 6.4507e-02   valLoss:9.7425e-01  time: 7.46e+00\n",
      "epoch: 41   trainLoss: 6.0263e-02   valLoss:1.0132e+00  time: 7.36e+00\n",
      "epoch: 42   trainLoss: 5.7689e-02   valLoss:2.8754e-01  time: 7.43e+00\n",
      "epoch: 43   trainLoss: 7.4663e-02   valLoss:9.5184e-01  time: 7.39e+00\n",
      "epoch: 44   trainLoss: 8.4234e-02   valLoss:6.4335e-01  time: 7.39e+00\n",
      "epoch: 45   trainLoss: 7.3614e-02   valLoss:3.0424e-01  time: 7.50e+00\n",
      "epoch: 46   trainLoss: 7.3749e-02   valLoss:5.9100e-01  time: 7.41e+00\n",
      "epoch: 47   trainLoss: 6.6450e-02   valLoss:4.8156e-01  time: 7.38e+00\n",
      "epoch: 48   trainLoss: 6.7452e-02   valLoss:8.2611e-01  time: 7.42e+00\n",
      "epoch: 49   trainLoss: 6.7590e-02   valLoss:2.5976e-01  time: 7.45e+00\n",
      "epoch: 50   trainLoss: 8.9285e-02   valLoss:5.3283e-01  time: 7.46e+00\n",
      "epoch: 51   trainLoss: 7.8437e-02   valLoss:7.8635e-01  time: 7.61e+00\n",
      "epoch: 52   trainLoss: 6.5239e-02   valLoss:4.2066e-01  time: 7.43e+00\n",
      "epoch: 53   trainLoss: 7.3985e-02   valLoss:2.8145e-01  time: 7.42e+00\n",
      "epoch: 54   trainLoss: 7.0071e-02   valLoss:1.7756e-01  time: 7.44e+00\n",
      "epoch: 55   trainLoss: 8.8851e-02   valLoss:3.1907e-01  time: 7.46e+00\n",
      "epoch: 56   trainLoss: 8.4353e-02   valLoss:6.4718e-01  time: 7.45e+00\n",
      "epoch: 57   trainLoss: 7.6276e-02   valLoss:7.2402e-01  time: 7.40e+00\n",
      "epoch: 58   trainLoss: 5.7462e-02   valLoss:4.2994e-01  time: 7.48e+00\n",
      "epoch: 59   trainLoss: 5.8824e-02   valLoss:1.2410e-01  time: 7.36e+00\n",
      "epoch: 60   trainLoss: 7.3163e-02   valLoss:2.2497e-01  time: 7.34e+00\n",
      "epoch: 61   trainLoss: 5.3030e-02   valLoss:1.9103e-01  time: 7.39e+00\n",
      "epoch: 62   trainLoss: 5.9061e-02   valLoss:3.5481e-01  time: 7.42e+00\n",
      "epoch: 63   trainLoss: 5.5926e-02   valLoss:2.5035e-01  time: 7.36e+00\n",
      "epoch: 64   trainLoss: 4.7916e-02   valLoss:1.5883e-01  time: 7.46e+00\n",
      "epoch: 65   trainLoss: 4.2456e-02   valLoss:1.0840e-01  time: 7.44e+00\n",
      "epoch: 66   trainLoss: 7.0200e-02   valLoss:2.1868e-01  time: 7.37e+00\n",
      "epoch: 67   trainLoss: 6.6679e-02   valLoss:2.3088e-01  time: 7.38e+00\n",
      "epoch: 68   trainLoss: 7.9529e-02   valLoss:6.8294e-02  time: 7.37e+00\n",
      "epoch: 69   trainLoss: 6.3002e-02   valLoss:3.3414e-01  time: 7.38e+00\n",
      "epoch: 70   trainLoss: 5.8170e-02   valLoss:3.3899e-01  time: 7.44e+00\n",
      "epoch: 71   trainLoss: 6.2999e-02   valLoss:2.5323e-01  time: 7.39e+00\n",
      "epoch: 72   trainLoss: 6.6807e-02   valLoss:4.2287e-01  time: 7.37e+00\n",
      "epoch: 73   trainLoss: 5.0831e-02   valLoss:1.7192e-01  time: 7.38e+00\n",
      "epoch: 74   trainLoss: 4.6037e-02   valLoss:8.8416e-02  time: 7.36e+00\n",
      "epoch: 75   trainLoss: 3.8418e-02   valLoss:9.4959e-02  time: 7.39e+00\n",
      "epoch: 76   trainLoss: 3.3523e-02   valLoss:9.8185e-02  time: 7.38e+00\n",
      "epoch: 77   trainLoss: 3.8510e-02   valLoss:8.2814e-02  time: 7.44e+00\n",
      "epoch: 78   trainLoss: 3.9678e-02   valLoss:1.7603e-01  time: 7.28e+00\n",
      "epoch: 79   trainLoss: 5.5131e-02   valLoss:7.0301e-02  time: 7.18e+00\n",
      "epoch: 80   trainLoss: 6.0918e-02   valLoss:1.9118e-01  time: 7.26e+00\n",
      "epoch: 81   trainLoss: 6.4139e-02   valLoss:2.0530e-01  time: 7.21e+00\n",
      "epoch: 82   trainLoss: 6.0397e-02   valLoss:1.9458e-01  time: 7.33e+00\n",
      "epoch: 83   trainLoss: 5.1446e-02   valLoss:9.2645e-02  time: 7.34e+00\n",
      "epoch: 84   trainLoss: 5.2933e-02   valLoss:2.6407e-01  time: 7.28e+00\n",
      "epoch: 85   trainLoss: 8.9224e-02   valLoss:1.5161e-01  time: 7.33e+00\n",
      "epoch: 86   trainLoss: 7.2816e-02   valLoss:1.3403e-01  time: 7.35e+00\n",
      "epoch: 87   trainLoss: 6.6900e-02   valLoss:1.1560e-01  time: 7.41e+00\n",
      "epoch: 88   trainLoss: 6.4901e-02   valLoss:1.6244e-01  time: 7.36e+00\n",
      "epoch: 89   trainLoss: 5.2871e-02   valLoss:5.8881e-02  time: 7.44e+00\n",
      "epoch: 90   trainLoss: 5.0566e-02   valLoss:6.6473e-02  time: 7.52e+00\n",
      "epoch: 91   trainLoss: 4.8966e-02   valLoss:1.6488e-01  time: 7.35e+00\n",
      "epoch: 92   trainLoss: 4.2113e-02   valLoss:5.7982e-02  time: 7.38e+00\n",
      "epoch: 93   trainLoss: 4.5574e-02   valLoss:1.0184e-01  time: 7.33e+00\n",
      "epoch: 94   trainLoss: 4.5556e-02   valLoss:3.7585e-02  time: 7.37e+00\n",
      "epoch: 95   trainLoss: 4.3292e-02   valLoss:6.5619e-02  time: 7.28e+00\n",
      "epoch: 96   trainLoss: 4.8617e-02   valLoss:6.6909e-02  time: 7.44e+00\n",
      "epoch: 97   trainLoss: 4.5451e-02   valLoss:6.5572e-02  time: 7.39e+00\n",
      "epoch: 98   trainLoss: 3.2689e-02   valLoss:6.2549e-02  time: 7.40e+00\n",
      "epoch: 99   trainLoss: 3.4613e-02   valLoss:6.9223e-02  time: 7.38e+00\n",
      "loading checkpoint 94\n",
      "loading restart file\n",
      "epoch: 0   trainLoss: 1.8016e-01   valLoss:8.9429e-01  time: 7.45e+00\n",
      "epoch: 1   trainLoss: 8.8673e-02   valLoss:4.9498e-01  time: 7.57e+00\n",
      "epoch: 2   trainLoss: 6.3028e-02   valLoss:8.8757e-02  time: 7.41e+00\n",
      "epoch: 3   trainLoss: 5.2687e-02   valLoss:8.3704e-02  time: 7.44e+00\n",
      "epoch: 4   trainLoss: 4.3401e-02   valLoss:8.1214e-02  time: 7.48e+00\n",
      "epoch: 5   trainLoss: 3.1187e-02   valLoss:4.3928e-02  time: 7.84e+00\n",
      "epoch: 6   trainLoss: 2.9149e-02   valLoss:6.7060e-02  time: 8.04e+00\n",
      "epoch: 7   trainLoss: 2.9763e-02   valLoss:3.3026e-02  time: 7.96e+00\n",
      "epoch: 8   trainLoss: 3.5178e-02   valLoss:7.1853e-02  time: 7.79e+00\n",
      "epoch: 9   trainLoss: 3.7088e-02   valLoss:4.1581e-02  time: 8.64e+00\n",
      "epoch: 10   trainLoss: 2.5001e-02   valLoss:6.1991e-02  time: 7.42e+00\n",
      "epoch: 11   trainLoss: 2.3258e-02   valLoss:2.6170e-02  time: 7.40e+00\n",
      "epoch: 12   trainLoss: 2.0063e-02   valLoss:4.3959e-02  time: 7.44e+00\n",
      "epoch: 13   trainLoss: 2.0566e-02   valLoss:3.6457e-02  time: 7.43e+00\n",
      "epoch: 14   trainLoss: 1.9638e-02   valLoss:2.3792e-02  time: 7.40e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15   trainLoss: 1.9803e-02   valLoss:5.1393e-02  time: 7.39e+00\n",
      "epoch: 16   trainLoss: 2.2266e-02   valLoss:5.0471e-02  time: 7.40e+00\n",
      "epoch: 17   trainLoss: 2.1903e-02   valLoss:5.7878e-02  time: 7.45e+00\n",
      "epoch: 18   trainLoss: 2.0197e-02   valLoss:5.7802e-02  time: 7.39e+00\n",
      "epoch: 19   trainLoss: 2.0244e-02   valLoss:2.4403e-02  time: 7.57e+00\n",
      "epoch: 20   trainLoss: 1.7766e-02   valLoss:5.2994e-02  time: 7.36e+00\n",
      "epoch: 21   trainLoss: 2.0940e-02   valLoss:2.4069e-02  time: 7.34e+00\n",
      "epoch: 22   trainLoss: 1.7526e-02   valLoss:4.9558e-02  time: 7.40e+00\n",
      "epoch: 23   trainLoss: 1.7983e-02   valLoss:2.1987e-02  time: 7.41e+00\n",
      "epoch: 24   trainLoss: 1.3650e-02   valLoss:6.6442e-02  time: 7.40e+00\n",
      "epoch: 25   trainLoss: 1.5327e-02   valLoss:2.0136e-02  time: 7.48e+00\n",
      "epoch: 26   trainLoss: 1.6475e-02   valLoss:2.9214e-02  time: 7.52e+00\n",
      "epoch: 27   trainLoss: 2.2225e-02   valLoss:2.9037e-02  time: 7.57e+00\n",
      "epoch: 28   trainLoss: 1.4874e-02   valLoss:3.3974e-02  time: 7.84e+00\n",
      "epoch: 29   trainLoss: 2.0484e-02   valLoss:7.5410e-02  time: 7.47e+00\n",
      "epoch: 30   trainLoss: 2.0008e-02   valLoss:4.5440e-02  time: 7.51e+00\n",
      "epoch: 31   trainLoss: 1.5850e-02   valLoss:5.7175e-02  time: 7.44e+00\n",
      "epoch: 32   trainLoss: 1.4626e-02   valLoss:6.3717e-02  time: 7.57e+00\n",
      "epoch: 33   trainLoss: 2.3264e-02   valLoss:3.6041e-02  time: 7.43e+00\n",
      "epoch: 34   trainLoss: 2.2308e-02   valLoss:4.8617e-02  time: 7.41e+00\n",
      "epoch: 35   trainLoss: 2.1567e-02   valLoss:2.6687e-02  time: 7.50e+00\n",
      "epoch: 36   trainLoss: 2.2279e-02   valLoss:4.9468e-02  time: 7.43e+00\n",
      "epoch: 37   trainLoss: 2.2555e-02   valLoss:7.7733e-02  time: 7.43e+00\n",
      "epoch: 38   trainLoss: 2.0158e-02   valLoss:2.5242e-02  time: 7.49e+00\n",
      "epoch: 39   trainLoss: 1.8558e-02   valLoss:5.8721e-02  time: 7.40e+00\n",
      "epoch: 40   trainLoss: 1.6999e-02   valLoss:4.3405e-02  time: 7.51e+00\n",
      "epoch: 41   trainLoss: 2.0967e-02   valLoss:4.7289e-02  time: 7.45e+00\n",
      "epoch: 42   trainLoss: 1.7607e-02   valLoss:2.3444e-02  time: 7.36e+00\n",
      "epoch: 43   trainLoss: 1.4616e-02   valLoss:3.0807e-02  time: 7.44e+00\n",
      "epoch: 44   trainLoss: 2.4605e-02   valLoss:4.1344e-02  time: 7.45e+00\n",
      "epoch: 45   trainLoss: 2.2979e-02   valLoss:4.8190e-02  time: 7.49e+00\n",
      "epoch: 46   trainLoss: 1.9705e-02   valLoss:4.5650e-02  time: 7.45e+00\n",
      "epoch: 47   trainLoss: 1.8567e-02   valLoss:8.5973e-02  time: 7.40e+00\n",
      "epoch: 48   trainLoss: 1.6952e-02   valLoss:1.9458e-02  time: 7.47e+00\n",
      "epoch: 49   trainLoss: 1.6758e-02   valLoss:3.1073e-02  time: 7.35e+00\n",
      "epoch: 50   trainLoss: 1.4565e-02   valLoss:2.1443e-02  time: 7.54e+00\n",
      "epoch: 51   trainLoss: 1.8315e-02   valLoss:2.4906e-02  time: 7.70e+00\n",
      "epoch: 52   trainLoss: 1.4457e-02   valLoss:7.4730e-02  time: 7.39e+00\n",
      "epoch: 53   trainLoss: 2.0610e-02   valLoss:1.8426e-02  time: 7.42e+00\n",
      "epoch: 54   trainLoss: 1.8555e-02   valLoss:3.2709e-02  time: 7.41e+00\n",
      "epoch: 55   trainLoss: 2.1250e-02   valLoss:9.1067e-02  time: 7.36e+00\n",
      "epoch: 56   trainLoss: 1.7806e-02   valLoss:3.9688e-02  time: 7.34e+00\n",
      "epoch: 57   trainLoss: 1.7842e-02   valLoss:3.7251e-02  time: 7.47e+00\n",
      "epoch: 58   trainLoss: 1.5393e-02   valLoss:1.0894e-01  time: 7.41e+00\n",
      "epoch: 59   trainLoss: 1.7882e-02   valLoss:3.0438e-02  time: 7.28e+00\n",
      "epoch: 60   trainLoss: 1.8929e-02   valLoss:2.2010e-02  time: 7.62e+00\n",
      "epoch: 61   trainLoss: 1.5115e-02   valLoss:3.1395e-02  time: 7.69e+00\n",
      "epoch: 62   trainLoss: 1.8147e-02   valLoss:4.2524e-02  time: 7.70e+00\n",
      "epoch: 63   trainLoss: 1.5459e-02   valLoss:3.7262e-02  time: 7.61e+00\n",
      "epoch: 64   trainLoss: 1.2200e-02   valLoss:1.9837e-02  time: 7.49e+00\n",
      "epoch: 65   trainLoss: 1.3960e-02   valLoss:3.7033e-02  time: 7.57e+00\n",
      "epoch: 66   trainLoss: 1.1630e-02   valLoss:4.0934e-02  time: 7.62e+00\n",
      "epoch: 67   trainLoss: 1.2491e-02   valLoss:2.5318e-02  time: 7.67e+00\n",
      "epoch: 68   trainLoss: 1.4304e-02   valLoss:3.4470e-02  time: 7.42e+00\n",
      "epoch: 69   trainLoss: 1.7313e-02   valLoss:5.2610e-02  time: 7.49e+00\n",
      "epoch: 70   trainLoss: 1.8330e-02   valLoss:3.0737e-02  time: 7.36e+00\n",
      "epoch: 71   trainLoss: 1.8444e-02   valLoss:5.1411e-02  time: 7.53e+00\n",
      "epoch: 72   trainLoss: 1.7208e-02   valLoss:4.0324e-02  time: 7.41e+00\n",
      "epoch: 73   trainLoss: 1.3869e-02   valLoss:3.8821e-02  time: 7.46e+00\n",
      "epoch: 74   trainLoss: 1.4185e-02   valLoss:5.4203e-02  time: 7.48e+00\n",
      "epoch: 75   trainLoss: 1.9712e-02   valLoss:3.5126e-02  time: 7.60e+00\n",
      "epoch: 76   trainLoss: 1.9906e-02   valLoss:4.1054e-02  time: 7.69e+00\n",
      "epoch: 77   trainLoss: 1.9011e-02   valLoss:7.0680e-02  time: 7.60e+00\n",
      "epoch: 78   trainLoss: 1.6040e-02   valLoss:3.4751e-02  time: 7.43e+00\n",
      "epoch: 79   trainLoss: 1.5457e-02   valLoss:3.3083e-02  time: 7.51e+00\n",
      "epoch: 80   trainLoss: 1.5745e-02   valLoss:2.6204e-02  time: 7.50e+00\n",
      "epoch: 81   trainLoss: 1.6792e-02   valLoss:3.9949e-02  time: 7.58e+00\n",
      "epoch: 82   trainLoss: 1.4212e-02   valLoss:2.9613e-02  time: 7.57e+00\n",
      "epoch: 83   trainLoss: 1.4943e-02   valLoss:2.8303e-02  time: 7.48e+00\n",
      "epoch: 84   trainLoss: 2.0210e-02   valLoss:5.6247e-02  time: 7.48e+00\n",
      "epoch: 85   trainLoss: 1.0575e-02   valLoss:6.1723e-02  time: 7.67e+00\n",
      "epoch: 86   trainLoss: 1.3902e-02   valLoss:4.3562e-02  time: 7.39e+00\n",
      "epoch: 87   trainLoss: 1.2092e-02   valLoss:2.1384e-02  time: 7.37e+00\n",
      "epoch: 88   trainLoss: 1.0890e-02   valLoss:2.3185e-02  time: 7.64e+00\n",
      "epoch: 89   trainLoss: 1.0898e-02   valLoss:3.5496e-02  time: 7.60e+00\n",
      "epoch: 90   trainLoss: 1.3478e-02   valLoss:8.4193e-02  time: 7.41e+00\n",
      "epoch: 91   trainLoss: 1.1302e-02   valLoss:2.4533e-02  time: 7.44e+00\n",
      "epoch: 92   trainLoss: 1.0945e-02   valLoss:2.9358e-02  time: 7.48e+00\n",
      "epoch: 93   trainLoss: 1.2649e-02   valLoss:2.6576e-02  time: 7.49e+00\n",
      "epoch: 94   trainLoss: 1.2335e-02   valLoss:2.6496e-02  time: 7.58e+00\n",
      "epoch: 95   trainLoss: 1.2303e-02   valLoss:1.7449e-02  time: 7.52e+00\n",
      "epoch: 96   trainLoss: 1.3042e-02   valLoss:5.8719e-02  time: 7.51e+00\n",
      "epoch: 97   trainLoss: 1.4304e-02   valLoss:2.4569e-02  time: 7.43e+00\n",
      "epoch: 98   trainLoss: 1.1940e-02   valLoss:2.9479e-02  time: 7.40e+00\n",
      "epoch: 99   trainLoss: 1.8325e-02   valLoss:2.1881e-02  time: 7.41e+00\n",
      "loading checkpoint 95\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/transferLrn_endloads_des7_02/testResults.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e1353d12fd8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mtestRes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Train Size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mallResults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestRes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallResults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveDir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'testResults.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/ptgeom/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m         )\n\u001b[0;32m-> 3204\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/ptgeom/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             )\n\u001b[1;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/ptgeom/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/transferLrn_endloads_des7_02/testResults.csv'"
     ]
    }
   ],
   "source": [
    "trainDataDirs = glob.glob(os.path.join(dataDir, 'design_7*/'))\n",
    "trainDataDirs.remove(testDir)\n",
    "\n",
    "allResults = []\n",
    "for trainDataDir in trainDataDirs:\n",
    "    trainDataUnfiltered = loadConmechGraphs(trainDataDir)\n",
    "    trainData = filterbyDispValue(trainDataUnfiltered, maxDispCutoff)\n",
    "    trainSize = len(trainData)\n",
    "    print(f'loaded train set of size {trainSize}')\n",
    "    \n",
    "    \n",
    "    ### fresh neural network ###\n",
    "    gcn = FeaStNet()\n",
    "    history = gcn.trainModel(trainData, trainData, \n",
    "                         epochs=epochs, \n",
    "                         saveDir=saveDir+f'{trainSize:05}/gcn/')\n",
    "    \n",
    "    trainRes = gcn.testModel(trainData)\n",
    "    trainRes['Model'] = 'Fresh'\n",
    "    trainRes['Set'] = 'Train'\n",
    "    trainRes['Train Size'] = trainSize\n",
    "    allResults.append(trainRes)\n",
    "    \n",
    "    testRes = gcn.testModel(testData)\n",
    "    testRes['Model'] = 'Fresh'\n",
    "    testRes['Set'] = 'Test'\n",
    "    testRes['Train Size'] = trainSize\n",
    "    allResults.append(testRes)\n",
    "    pd.DataFrame(allResults).to_csv(saveDir+'testResults.csv', index=False)\n",
    "\n",
    "    \n",
    "    ### transfer learning ###\n",
    "    ptrGcn = FeaStNet()\n",
    "    history = gcn.trainModel(trainData, trainData, \n",
    "                             restartFile=ptrGcnCheckptFile,\n",
    "                             epochs=epochs, \n",
    "                             saveDir=saveDir+f'{trainSize:05}/ptrGcn/')\n",
    "    \n",
    "    trainRes = gcn.testModel(trainData)\n",
    "    trainRes['Model'] = 'Transfer learning'\n",
    "    trainRes['Set'] = 'Train'\n",
    "    trainRes['Train Size'] = trainSize\n",
    "    allResults.append(trainRes)\n",
    "    \n",
    "    testRes = gcn.testModel(testData)\n",
    "    testRes['Model'] = 'Transfer learning'\n",
    "    testRes['Set'] = 'Test'\n",
    "    testRes['Train Size'] = trainSize\n",
    "    allResults.append(testRes)\n",
    "    pd.DataFrame(allResults).to_csv(saveDir+'testResults.csv', index=False)\n",
    "    \n",
    "    \n",
    "    ### random forest ###\n",
    "    rf = PointRegressor('Random Forest')\n",
    "    rf.trainModel(trainData, trainData, \n",
    "                  useXFeatures=False,\n",
    "                  saveDir=saveDir+f'{trainSize:05}/rf/')\n",
    "\n",
    "    trainRes = rf.testModel(trainData)\n",
    "    trainRes['Model'] = 'Random Forest'\n",
    "    trainRes['Set'] = 'Train'\n",
    "    trainRes['Train Size'] = trainSize\n",
    "    allResults.append(trainRes)\n",
    "    \n",
    "    testRes = rf.testModel(testData)\n",
    "    testRes['Model'] = 'Random Forest'\n",
    "    testRes['Set'] = 'Test'\n",
    "    testRes['Train Size'] = trainSize\n",
    "    allResults.append(testRes)\n",
    "    pd.DataFrame(allResults).to_csv(saveDir+'testResults.csv', index=False)\n",
    "    \n",
    "    \n",
    "pd.DataFrame(allResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(allResults)\n",
    "df = pd.read_csv('results/transferLrn_endloads_des7_02/testResults.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('Fresh', 'GCN')\n",
    "df = df.replace('Transfer learning', 'GCN with transfer learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df[df.Set=='Test']).mark_circle().encode(\n",
    "    x=alt.X('Train Size:Q', scale=alt.Scale(type='log')),\n",
    "    y=alt.Y('mse:Q', title='MSE', axis=alt.Axis(format='.1e')),\n",
    "    color='Model',\n",
    "    tooltip=['Model', 'mse']\n",
    ").properties(width=400, height=200, title='Transfer learning - group 7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptgeom",
   "language": "python",
   "name": "ptgeom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
